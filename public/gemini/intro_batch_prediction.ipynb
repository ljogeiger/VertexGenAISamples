{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Intro to Batch Predictions with the Gemini API\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/batch-prediction/intro_batch_prediction.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fbatch-prediction%2Fintro_batch_prediction.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/batch-prediction/intro_batch_prediction.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/bigquery/import?url=https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/batch-prediction/intro_batch_prediction.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/bigquery/v1/32px.svg\" alt=\"BigQuery Studio logo\"><br> Open in BigQuery Studio\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/batch-prediction/intro_batch_prediction.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/batch-prediction/intro_batch_prediction.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/batch-prediction/intro_batch_prediction.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/batch-prediction/intro_batch_prediction.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/batch-prediction/intro_batch_prediction.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/batch-prediction/intro_batch_prediction.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0f73a0f76"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Eric Dong](https://github.com/gericdong), [Holt Skinner](https://github.com/holtskinner) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Different from getting online (synchronous) responses, where you are limited to one input request at a time, the batch predictions with the Gemini API in Vertex AI allow you to send a large number of multimodal requests to a Gemini model in a single batch request. Then, the model responses asynchronously populate to your storage output location in [Cloud Storage](https://cloud.google.com/storage/docs/introduction) or [BigQuery](https://cloud.google.com/bigquery/docs/storage_overview).\n",
        "\n",
        "Batch predictions are generally more efficient and cost-effective than online predictions when processing a large number of inputs that are not latency sensitive.\n",
        "\n",
        "To learn more, see the [Get batch predictions for Gemini](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/batch-prediction-gemini) page.\n",
        "\n",
        "### Objectives\n",
        "\n",
        "In this tutorial, you learn how to make batch predictions with the Gemini API in Vertex AI. This tutorial shows how to use **Cloud Storage** and **BigQuery** as input sources and output locations.\n",
        "\n",
        "You will complete the following tasks:\n",
        "\n",
        "- Preparing batch inputs and an output location\n",
        "- Submitting a batch prediction job\n",
        "- Retrieving batch prediction results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Google Gen AI SDK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-vertexai 1.0.10 requires google-cloud-storage<3.0.0,>=2.17.0, but you have google-cloud-storage 3.1.0 which is incompatible.\n",
            "langchain-google-vertexai 1.0.10 requires httpx<0.28.0,>=0.27.0, but you have httpx 0.28.1 which is incompatible.\n",
            "flet 0.24.1 requires packaging<24.0,>=23.1, but you have packaging 24.2 which is incompatible.\n",
            "google-cloud-aiplatform 1.82.0 requires google-cloud-storage<3.0.0dev,>=1.32.0, but you have google-cloud-storage 3.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet google-genai pandas google-cloud-storage google-cloud-bigquery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your browser has been opened to visit:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=0tMJYrrg5Atg5gJwQU4eEO3g2nlObZ&access_type=offline&code_challenge=xdtKoEeYzfrhLf7YJReyt7Rqg3iGFcfhX_CrYX2SHms&code_challenge_method=S256\n",
            "\n",
            "\n",
            "Credentials saved to file: [/Users/lukasgeiger/.config/gcloud/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\n",
            "Quota project \"sandbox-aiml\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
          ]
        }
      ],
      "source": [
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06489bd14f16"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fe00fa0b8bb7"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "import fsspec\n",
        "from google import genai\n",
        "from google.cloud import bigquery\n",
        "from google.genai.types import CreateBatchJobConfig\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and create client\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"sandbox-aiml\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cfca4d7bd6db"
      },
      "outputs": [],
      "source": [
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e43229f3ad4f"
      },
      "source": [
        "### Load model\n",
        "\n",
        "You can find a list of the Gemini models that support batch predictions in the [Multimodal models that support batch predictions](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/batch-prediction-gemini#multimodal_models_that_support_batch_predictions) page.\n",
        "\n",
        "This tutorial uses Gemini 2.0 Flash (`gemini-2.0-flash-001`) model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cf93d5f0ce00"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.0-flash-001\"  # @param {type:\"string\", isTemplate: true}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "265f180b58e0"
      },
      "source": [
        "## Cloud Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_xZADsak23H"
      },
      "source": [
        "### Prepare batch inputs\n",
        "\n",
        "The input for batch requests specifies the items to send to your model for prediction. You can learn more about the batch input formats in the [Batch text generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/batch-prediction-gemini#prepare_your_inputs) page.\n",
        "\n",
        "This tutorial uses Cloud Storage as an example. The requirements for Cloud Storage input are:\n",
        "\n",
        "- File format: [JSON Lines (JSONL)](https://jsonlines.org/)\n",
        "- Located in `us-central1`\n",
        "- Appropriate read permissions for the service account\n",
        "\n",
        "Each request that you send to a model can include parameters that control how the model generates a response. Learn more about Gemini parameters in the [Experiment with parameter values](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values) page.\n",
        "\n",
        "This is one of the example requests in the input JSONL file `batch_requests_for_multimodal_input_2.jsonl`:\n",
        "\n",
        "```json\n",
        "{\"request\":{\"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": \"List objects in this image.\"}, {\"file_data\": {\"file_uri\": \"gs://cloud-samples-data/generative-ai/image/office-desk.jpeg\", \"mime_type\": \"image/jpeg\"}}]}],\"generationConfig\":{\"temperature\": 0.4}}}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "uWb8QzxwbH6W"
      },
      "outputs": [],
      "source": [
        "INPUT_DATA = \"gs://langchain-agent-bucket/batch_requests_for_multimodal_input_2.jsonl\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3jQ59mCsXLc"
      },
      "source": [
        "### Prepare batch output location\n",
        "\n",
        "When a batch prediction task completes, the output is stored in the location that you specified in your request.\n",
        "\n",
        "- The location is in the form of a Cloud Storage prefix.\n",
        "  - For example: `gs://path/to/output/data`.\n",
        "\n",
        "- You can specify the URI of your Cloud Storage bucket in `BUCKET_URI`, or\n",
        "- If it is not specified, this notebook will create a Cloud Storage bucket in the form of `gs://PROJECT_ID-TIMESTAMP`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "OtUodwGXZ7US"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating gs://sandbox-aiml-20250407170244/...\n"
          ]
        }
      ],
      "source": [
        "BUCKET_URI = \"[your-cloud-storage-bucket]\"  # @param {type:\"string\"}\n",
        "\n",
        "if BUCKET_URI == \"[your-cloud-storage-bucket]\":\n",
        "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "    BUCKET_URI = f\"gs://{PROJECT_ID}-{TIMESTAMP}\"\n",
        "\n",
        "    ! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T90CwWDHvonn"
      },
      "source": [
        "### Send a batch prediction request\n",
        "\n",
        "To make a batch prediction request, you specify a source model ID, an input source and an output location where Vertex AI stores the batch prediction results.\n",
        "\n",
        "To learn more, see the [Batch prediction API](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/batch-prediction-api) page.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "d8e54c57072e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'projects/305610648548/locations/us-central1/batchPredictionJobs/777330273883783168'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gcs_batch_job = client.batches.create(\n",
        "    model=MODEL_ID,\n",
        "    src=INPUT_DATA,\n",
        "    config=CreateBatchJobConfig(dest=BUCKET_URI),\n",
        ")\n",
        "gcs_batch_job.name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-Fo_Kd9FYRj"
      },
      "source": [
        "Print out the job status and other properties. You can also check the status in the Cloud Console at https://console.cloud.google.com/vertex-ai/batch-predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "DWq7m79PbjG8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BatchJob(name='projects/305610648548/locations/us-central1/batchPredictionJobs/777330273883783168', display_name='genai_batch_job_20250407170247_b984b', state=<JobState.JOB_STATE_RUNNING: 'JOB_STATE_RUNNING'>, error=None, create_time=datetime.datetime(2025, 4, 7, 21, 2, 48, 263250, tzinfo=TzInfo(UTC)), start_time=datetime.datetime(2025, 4, 7, 21, 2, 48, 376592, tzinfo=TzInfo(UTC)), end_time=None, update_time=datetime.datetime(2025, 4, 7, 21, 2, 49, 34328, tzinfo=TzInfo(UTC)), model='publishers/google/models/gemini-2.0-flash-001', src=BatchJobSource(format='jsonl', gcs_uri=['gs://langchain-agent-bucket/batch_requests_for_multimodal_input_2.jsonl'], bigquery_uri=None), dest=BatchJobDestination(format='jsonl', gcs_uri='gs://sandbox-aiml-20250407170244', bigquery_uri=None))"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gcs_batch_job = client.batches.get(name=gcs_batch_job.name)\n",
        "gcs_batch_job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHUUEREoiewD"
      },
      "source": [
        "Optionally, you can list all the batch prediction jobs in the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QVgOnasfigx1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "projects/305610648548/locations/us-central1/batchPredictionJobs/777330273883783168 2025-04-07 21:02:48.263250+00:00 JobState.JOB_STATE_RUNNING\n",
            "projects/305610648548/locations/us-central1/batchPredictionJobs/6053297237348319232 2025-04-07 21:00:08.853577+00:00 JobState.JOB_STATE_FAILED\n",
            "projects/305610648548/locations/us-central1/batchPredictionJobs/8944608198120177664 2025-04-07 20:53:28.031228+00:00 JobState.JOB_STATE_FAILED\n"
          ]
        }
      ],
      "source": [
        "for job in client.batches.list():\n",
        "    print(job.name, job.create_time, job.state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aJaPNBrGPqK"
      },
      "source": [
        "### Wait for the batch prediction job to complete\n",
        "\n",
        "Depending on the number of input items that you submitted, a batch generation task can take some time to complete. You can use the following code to check the job status and wait for the job to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "dtJDIXdHc0W-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Job succeeded!\n"
          ]
        }
      ],
      "source": [
        "# Refresh the job until complete\n",
        "while gcs_batch_job.state == \"JOB_STATE_RUNNING\":\n",
        "    time.sleep(5)\n",
        "    gcs_batch_job = client.batches.get(name=gcs_batch_job.name)\n",
        "\n",
        "# Check if the job succeeds\n",
        "if gcs_batch_job.state == \"JOB_STATE_SUCCEEDED\":\n",
        "    print(\"Job succeeded!\")\n",
        "else:\n",
        "    print(f\"Job failed: {gcs_batch_job.error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWUgAxL-HjN9"
      },
      "source": [
        "### Retrieve batch prediction results\n",
        "\n",
        "When a batch prediction task is complete, the output of the prediction is stored in the bucket in JSONL that you specified in your request.\n",
        "\n",
        "The file name should look like this: `{gcs_batch_job.dest.gcs_uri}/prediction-model-TIMESTAMP/predictions.jsonl`\n",
        "\n",
        "Example output:\n",
        "\n",
        "```json\n",
        "{\"status\":\"\",\"processed_time\":\"2025-04-07T21:05:52.328+00:00\",\"request\":{\"contents\":[{\"parts\":[{\"file_data\":null,\"text\":\"List objects in this image.\"},{\"file_data\":{\"file_uri\":\"gs://cloud-samples-data/generative-ai/image/office-desk.jpeg\",\"mime_type\":\"image/jpeg\"},\"text\":null}],\"role\":\"user\"}],\"generationConfig\":{\"responseMimeType\":\"application/json\",\"temperature\":0.4}},\"response\":{\"candidates\":[{\"avgLogprobs\":-0.05516629659829019,\"content\":{\"parts\":[{\"text\":\"[\\n  {\\\"label\\\": \\\"globe\\\"},\\n  {\\\"label\\\": \\\"Eiffel tower\\\"},\\n  {\\\"label\\\": \\\"airplane\\\"},\\n  {\\\"label\\\": \\\"passport\\\"},\\n  {\\\"label\\\": \\\"sunglasses\\\"},\\n  {\\\"label\\\": \\\"money\\\"},\\n  {\\\"label\\\": \\\"notebook\\\"},\\n  {\\\"label\\\": \\\"pen\\\"},\\n  {\\\"label\\\": \\\"tablet\\\"},\\n  {\\\"label\\\": \\\"shopping cart\\\"},\\n  {\\\"label\\\": \\\"gift\\\"},\\n  {\\\"label\\\": \\\"coffee\\\"},\\n  {\\\"label\\\": \\\"keyboard\\\"},\\n  {\\\"label\\\": \\\"mouse\\\"}\\n]\"}],\"role\":\"model\"},\"finishReason\":\"STOP\"}],\"createTime\":\"2025-04-07T21:05:52.603066Z\",\"modelVersion\":\"gemini-2.0-flash-001@default\",\"responseId\":\"MD70Z7rnJLWNhMIPjYHV6Ak\",\"usageMetadata\":{\"candidatesTokenCount\":119,\"candidatesTokensDetails\":[{\"modality\":\"TEXT\",\"tokenCount\":119}],\"promptTokenCount\":1812,\"promptTokensDetails\":[{\"modality\":\"TEXT\",\"tokenCount\":6},{\"modality\":\"IMAGE\",\"tokenCount\":1806}],\"totalTokenCount\":1931,\"trafficType\":\"ON_DEMAND\"}}}\n",
        "{\"status\":\"\",\"processed_time\":\"2025-04-07T21:05:52.331+00:00\",\"request\":{\"contents\":[{\"parts\":[{\"file_data\":null,\"text\":\"List objects in this image.\"},{\"file_data\":{\"file_uri\":\"gs://cloud-samples-data/generative-ai/image/gardening-tools.jpeg\",\"mime_type\":\"image/jpeg\"},\"text\":null}],\"role\":\"user\"}],\"generationConfig\":{\"responseMimeType\":\"application/json\",\"temperature\":0.4}},\"response\":{\"candidates\":[{\"avgLogprobs\":-0.18555694971329126,\"content\":{\"parts\":[{\"text\":\"[\\n  \\\"watering can\\\",\\n  \\\"flowerpot\\\",\\n  \\\"plant\\\",\\n  \\\"gardening glove\\\",\\n  \\\"trowel\\\",\\n  \\\"hoe\\\"\\n]\"}],\"role\":\"model\"},\"finishReason\":\"STOP\"}],\"createTime\":\"2025-04-07T21:05:52.652430Z\",\"modelVersion\":\"gemini-2.0-flash-001@default\",\"responseId\":\"MD70Z47pJ6WQhMIP1PiMsQI\",\"usageMetadata\":{\"candidatesTokenCount\":39,\"candidatesTokensDetails\":[{\"modality\":\"TEXT\",\"tokenCount\":39}],\"promptTokenCount\":1812,\"promptTokensDetails\":[{\"modality\":\"IMAGE\",\"tokenCount\":1806},{\"modality\":\"TEXT\",\"tokenCount\":6}],\"totalTokenCount\":1851,\"trafficType\":\"ON_DEMAND\"}}}\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZlRIYsC01F1"
      },
      "source": [
        "The example code below shows how to load the `.jsonl` file in the Cloud Storage output location into a Pandas DataFrame and print out the object.\n",
        "\n",
        "You can retrieve the specific responses in the `response` field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "  Downloading gcsfs-2025.3.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gcsfs) (3.11.13)\n",
            "Requirement already satisfied: decorator>4.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gcsfs) (5.1.1)\n",
            "Collecting fsspec==2025.3.2 (from gcsfs)\n",
            "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: google-auth>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gcsfs) (2.38.0)\n",
            "Collecting google-auth-oauthlib (from gcsfs)\n",
            "  Using cached google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: google-cloud-storage in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gcsfs) (3.1.0)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gcsfs) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.18.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth>=1.2->gcsfs) (4.9)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib->gcsfs)\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (2.24.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.4.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-cloud-storage->gcsfs) (1.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->gcsfs) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->gcsfs) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->gcsfs) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->gcsfs) (2024.12.14)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (5.29.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.25.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n",
            "Downloading gcsfs-2025.3.2-py2.py3-none-any.whl (36 kB)\n",
            "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Using cached google_auth_oauthlib-1.2.1-py2.py3-none-any.whl (24 kB)\n",
            "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Installing collected packages: fsspec, requests-oauthlib, google-auth-oauthlib, gcsfs\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.12.0\n",
            "    Uninstalling fsspec-2024.12.0:\n",
            "      Successfully uninstalled fsspec-2024.12.0\n",
            "Successfully installed fsspec-2025.3.2 gcsfs-2025.3.2 google-auth-oauthlib-1.2.1 requests-oauthlib-2.0.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install gcsfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "-jLl3es3dTqB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "_request out of retries on exception: Cannot connect to host storage.googleapis.com:443 ssl:True [SSLCertVerificationError: (1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')]\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py\", line 1123, in _wrap_create_connection\n",
            "    connection = await self._loop.create_connection(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1112, in create_connection\n",
            "    transport, protocol = await self._create_connection_transport(\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1145, in _create_connection_transport\n",
            "    await waiter\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/sslproto.py\", line 575, in _on_handshake_complete\n",
            "    raise handshake_exc\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/sslproto.py\", line 557, in _do_handshake\n",
            "    self._sslobj.do_handshake()\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py\", line 979, in do_handshake\n",
            "    self._sslobj.do_handshake()\n",
            "ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gcsfs/retry.py\", line 135, in retry_request\n",
            "    return await func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gcsfs/core.py\", line 456, in _request\n",
            "    async with self.session.request(\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n",
            "    self._resp: _RetType = await self._coro\n",
            "                           ^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/client.py\", line 703, in _request\n",
            "    conn = await self._connector.connect(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py\", line 548, in connect\n",
            "    proto = await self._create_connection(req, traces, timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n",
            "    _, proto = await self._create_direct_connection(req, traces, timeout)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py\", line 1411, in _create_direct_connection\n",
            "    raise last_exc\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py\", line 1380, in _create_direct_connection\n",
            "    transp, proto = await self._wrap_create_connection(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py\", line 1129, in _wrap_create_connection\n",
            "    raise ClientConnectorCertificateError(req.connection_key, exc) from exc\n",
            "aiohttp.client_exceptions.ClientConnectorCertificateError: Cannot connect to host storage.googleapis.com:443 ssl:True [SSLCertVerificationError: (1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')]\n"
          ]
        },
        {
          "ename": "ClientConnectorCertificateError",
          "evalue": "Cannot connect to host storage.googleapis.com:443 ssl:True [SSLCertVerificationError: (1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py:1123\u001b[0m, in \u001b[0;36mTCPConnector._wrap_create_connection\u001b[0;34m(self, addr_infos, req, timeout, client_error, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m aiohappyeyeballs\u001b[38;5;241m.\u001b[39mstart_connection(\n\u001b[1;32m   1117\u001b[0m     addr_infos\u001b[38;5;241m=\u001b[39maddr_infos,\n\u001b[1;32m   1118\u001b[0m     local_addr_infos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_addr_infos,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1121\u001b[0m     loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop,\n\u001b[1;32m   1122\u001b[0m )\n\u001b[0;32m-> 1123\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, sock\u001b[38;5;241m=\u001b[39msock\n\u001b[1;32m   1125\u001b[0m )\n\u001b[1;32m   1126\u001b[0m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py:1112\u001b[0m, in \u001b[0;36mBaseEventLoop.create_connection\u001b[0;34m(self, protocol_factory, host, port, ssl, family, proto, flags, sock, local_addr, server_hostname, ssl_handshake_timeout, ssl_shutdown_timeout, happy_eyeballs_delay, interleave)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1110\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA Stream Socket was expected, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msock\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1112\u001b[0m transport, protocol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_transport(\n\u001b[1;32m   1113\u001b[0m     sock, protocol_factory, ssl, server_hostname,\n\u001b[1;32m   1114\u001b[0m     ssl_handshake_timeout\u001b[38;5;241m=\u001b[39mssl_handshake_timeout,\n\u001b[1;32m   1115\u001b[0m     ssl_shutdown_timeout\u001b[38;5;241m=\u001b[39mssl_shutdown_timeout)\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_debug:\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;66;03m# Get the socket from the transport because SSL transport closes\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;66;03m# the old socket and creates a new SSL socket\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py:1145\u001b[0m, in \u001b[0;36mBaseEventLoop._create_connection_transport\u001b[0;34m(self, sock, protocol_factory, ssl, server_hostname, server_side, ssl_handshake_timeout, ssl_shutdown_timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1145\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/sslproto.py:575\u001b[0m, in \u001b[0;36mSSLProtocol._on_handshake_complete\u001b[0;34m(self, handshake_exc)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m handshake_exc\n\u001b[1;32m    577\u001b[0m peercert \u001b[38;5;241m=\u001b[39m sslobj\u001b[38;5;241m.\u001b[39mgetpeercert()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/sslproto.py:557\u001b[0m, in \u001b[0;36mSSLProtocol._do_handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 557\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLAgainErrors:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:979\u001b[0m, in \u001b[0;36mSSLObject.do_handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Start the SSL/TLS handshake.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 979\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mdo_handshake()\n",
            "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mClientConnectorCertificateError\u001b[0m           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m fs \u001b[38;5;241m=\u001b[39m fsspec\u001b[38;5;241m.\u001b[39mfilesystem(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgcs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgcs_batch_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcs_uri\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/*/predictions.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gcs_batch_job\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJOB_STATE_SUCCEEDED\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Load the JSONL file into a DataFrame\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_paths[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fsspec/asyn.py:118\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fsspec/asyn.py:103\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fsspec/asyn.py:56\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     54\u001b[0m     coro \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     58\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m ex\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fsspec/asyn.py:820\u001b[0m, in \u001b[0;36mAsyncFileSystem._glob\u001b[0;34m(self, path, maxdepth, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    818\u001b[0m         depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 820\u001b[0m allpaths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find(\n\u001b[1;32m    821\u001b[0m     root, maxdepth\u001b[38;5;241m=\u001b[39mdepth, withdirs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, detail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    822\u001b[0m )\n\u001b[1;32m    824\u001b[0m pattern \u001b[38;5;241m=\u001b[39m glob_translate(path \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ends_with_sep \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    825\u001b[0m pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(pattern)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gcsfs/core.py:1507\u001b[0m, in \u001b[0;36mGCSFileSystem._find\u001b[0;34m(self, path, withdirs, detail, prefix, versions, maxdepth, **kwargs)\u001b[0m\n\u001b[1;32m   1504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxdepth must be at least 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;66;03m# Fetch objects as if the path is a directory\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m objects, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_list_objects(\n\u001b[1;32m   1508\u001b[0m     path, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, prefix\u001b[38;5;241m=\u001b[39mprefix, versions\u001b[38;5;241m=\u001b[39mversions\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m objects:\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# Fetch objects as if the path is a file\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     bucket, key, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_path(path)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gcsfs/core.py:679\u001b[0m, in \u001b[0;36mGCSFileSystem._do_list_objects\u001b[0;34m(self, path, max_results, delimiter, prefix, versions, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concurrent_list_objects_helper(\n\u001b[1;32m    668\u001b[0m         items\u001b[38;5;241m=\u001b[39mitems,\n\u001b[1;32m    669\u001b[0m         bucket\u001b[38;5;241m=\u001b[39mbucket,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    673\u001b[0m         page_size\u001b[38;5;241m=\u001b[39mdefault_page_size,\n\u001b[1;32m    674\u001b[0m     )\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m# If the user has not configured inventory report, proceed to use\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;66;03m# sequential listing.\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sequential_list_objects_helper(\n\u001b[1;32m    680\u001b[0m         bucket\u001b[38;5;241m=\u001b[39mbucket,\n\u001b[1;32m    681\u001b[0m         delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[1;32m    682\u001b[0m         start_offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    683\u001b[0m         end_offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    684\u001b[0m         prefix\u001b[38;5;241m=\u001b[39mprefix,\n\u001b[1;32m    685\u001b[0m         versions\u001b[38;5;241m=\u001b[39mversions,\n\u001b[1;32m    686\u001b[0m         page_size\u001b[38;5;241m=\u001b[39mdefault_page_size,\n\u001b[1;32m    687\u001b[0m     )\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gcsfs/core.py:773\u001b[0m, in \u001b[0;36mGCSFileSystem._sequential_list_objects_helper\u001b[0;34m(self, bucket, delimiter, start_offset, end_offset, prefix, versions, page_size)\u001b[0m\n\u001b[1;32m    770\u001b[0m prefixes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    771\u001b[0m items \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 773\u001b[0m page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/o\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    776\u001b[0m     bucket,\n\u001b[1;32m    777\u001b[0m     delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[1;32m    778\u001b[0m     prefix\u001b[38;5;241m=\u001b[39mprefix,\n\u001b[1;32m    779\u001b[0m     startOffset\u001b[38;5;241m=\u001b[39mstart_offset,\n\u001b[1;32m    780\u001b[0m     endOffset\u001b[38;5;241m=\u001b[39mend_offset,\n\u001b[1;32m    781\u001b[0m     maxResults\u001b[38;5;241m=\u001b[39mpage_size,\n\u001b[1;32m    782\u001b[0m     json_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    783\u001b[0m     versions\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m versions \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    784\u001b[0m )\n\u001b[1;32m    786\u001b[0m prefixes\u001b[38;5;241m.\u001b[39mextend(page\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefixes\u001b[39m\u001b[38;5;124m\"\u001b[39m, []))\n\u001b[1;32m    787\u001b[0m items\u001b[38;5;241m.\u001b[39mextend(page\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m\"\u001b[39m, []))\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gcsfs/core.py:477\u001b[0m, in \u001b[0;36mGCSFileSystem._call\u001b[0;34m(self, method, path, json_out, info_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28mself\u001b[39m, method, path, \u001b[38;5;241m*\u001b[39margs, json_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, info_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    475\u001b[0m ):\n\u001b[1;32m    476\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 477\u001b[0m     status, headers, info, contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    478\u001b[0m         method, path, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    479\u001b[0m     )\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m json_out:\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(contents)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/decorator.py:221\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    220\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gcsfs/retry.py:165\u001b[0m, in \u001b[0;36mretry_request\u001b[0;34m(func, retries, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;241m==\u001b[39m retries \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    164\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of retries on exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_retriable(e):\n\u001b[1;32m    167\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m retrying after exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gcsfs/retry.py:135\u001b[0m, in \u001b[0;36mretry_request\u001b[0;34m(func, retries, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mmin\u001b[39m(random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (retry \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m32\u001b[39m))\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    137\u001b[0m     HttpError,\n\u001b[1;32m    138\u001b[0m     requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     aiohttp\u001b[38;5;241m.\u001b[39mclient_exceptions\u001b[38;5;241m.\u001b[39mClientError,\n\u001b[1;32m    142\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(e, HttpError)\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequester pays\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m    147\u001b[0m     ):\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gcsfs/core.py:456\u001b[0m, in \u001b[0;36mGCSFileSystem._request\u001b[0;34m(self, method, path, headers, json, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseek\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    455\u001b[0m     data\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    457\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    458\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_path(path, args),\n\u001b[1;32m    459\u001b[0m     params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_params(kwargs),\n\u001b[1;32m    460\u001b[0m     json\u001b[38;5;241m=\u001b[39mjson,\n\u001b[1;32m    461\u001b[0m     headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_headers(headers),\n\u001b[1;32m    462\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    463\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequests_timeout,\n\u001b[1;32m    464\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m r:\n\u001b[1;32m    465\u001b[0m     status \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    466\u001b[0m     headers \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mheaders\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/client.py:1425\u001b[0m, in \u001b[0;36m_BaseRequestContextManager.__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _RetType:\n\u001b[0;32m-> 1425\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp: _RetType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coro\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__aenter__\u001b[39m()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/client.py:703\u001b[0m, in \u001b[0;36mClientSession._request\u001b[0;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, server_hostname, proxy_headers, trace_request_ctx, read_bufsize, auto_decompress, max_line_size, max_field_size)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;66;03m# connection timeout\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 703\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[1;32m    704\u001b[0m         req, traces\u001b[38;5;241m=\u001b[39mtraces, timeout\u001b[38;5;241m=\u001b[39mreal_timeout\n\u001b[1;32m    705\u001b[0m     )\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mTimeoutError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectionTimeoutError(\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection timeout to host \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py:548\u001b[0m, in \u001b[0;36mBaseConnector.connect\u001b[0;34m(self, req, traces, timeout)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m traces:\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m trace\u001b[38;5;241m.\u001b[39msend_connection_create_start()\n\u001b[0;32m--> 548\u001b[0m proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection(req, traces, timeout)\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m traces:\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m traces:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py:1056\u001b[0m, in \u001b[0;36mTCPConnector._create_connection\u001b[0;34m(self, req, traces, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m     _, proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_proxy_connection(req, traces, timeout)\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1056\u001b[0m     _, proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_direct_connection(req, traces, timeout)\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m proto\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py:1411\u001b[0m, in \u001b[0;36mTCPConnector._create_direct_connection\u001b[0;34m(self, req, traces, timeout, client_error)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m last_exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m last_exc\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py:1380\u001b[0m, in \u001b[0;36mTCPConnector._create_direct_connection\u001b[0;34m(self, req, traces, timeout, client_error)\u001b[0m\n\u001b[1;32m   1375\u001b[0m server_hostname \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1376\u001b[0m     (req\u001b[38;5;241m.\u001b[39mserver_hostname \u001b[38;5;129;01mor\u001b[39;00m host)\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m sslcontext \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m )\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1380\u001b[0m     transp, proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_create_connection(\n\u001b[1;32m   1381\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_factory,\n\u001b[1;32m   1382\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1383\u001b[0m         ssl\u001b[38;5;241m=\u001b[39msslcontext,\n\u001b[1;32m   1384\u001b[0m         addr_infos\u001b[38;5;241m=\u001b[39maddr_infos,\n\u001b[1;32m   1385\u001b[0m         server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[1;32m   1386\u001b[0m         req\u001b[38;5;241m=\u001b[39mreq,\n\u001b[1;32m   1387\u001b[0m         client_error\u001b[38;5;241m=\u001b[39mclient_error,\n\u001b[1;32m   1388\u001b[0m     )\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ClientConnectorError, asyncio\u001b[38;5;241m.\u001b[39mTimeoutError) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1390\u001b[0m     last_exc \u001b[38;5;241m=\u001b[39m exc\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aiohttp/connector.py:1129\u001b[0m, in \u001b[0;36mTCPConnector._wrap_create_connection\u001b[0;34m(self, addr_infos, req, timeout, client_error, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m cert_errors \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 1129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientConnectorCertificateError(req\u001b[38;5;241m.\u001b[39mconnection_key, exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ssl_errors \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientConnectorSSLError(req\u001b[38;5;241m.\u001b[39mconnection_key, exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
            "\u001b[0;31mClientConnectorCertificateError\u001b[0m: Cannot connect to host storage.googleapis.com:443 ssl:True [SSLCertVerificationError: (1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')]"
          ]
        }
      ],
      "source": [
        "fs = fsspec.filesystem(\"gcs\")\n",
        "\n",
        "file_paths = fs.glob(f\"{gcs_batch_job.dest.gcs_uri}/*/predictions.jsonl\")\n",
        "\n",
        "if gcs_batch_job.state == \"JOB_STATE_SUCCEEDED\":\n",
        "    # Load the JSONL file into a DataFrame\n",
        "    df = pd.read_json(f\"gs://{file_paths[0]}\", lines=True)\n",
        "\n",
        "    df = df.join(pd.json_normalize(df[\"response\"], \"candidates\"))\n",
        "    display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfb2a462a7c6"
      },
      "source": [
        "## BigQuery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ea69e283023"
      },
      "source": [
        "### Batch Input Preparation  \n",
        "\n",
        "To send batch requests for prediction, you need to structure your input properly. For more details, visit the [Batch text generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/batch-prediction-gemini#prepare_your_inputs) page.  \n",
        "\n",
        "This guide uses **BigQuery** as an example. To use a BigQuery table as input:  \n",
        "- Ensure the dataset is created in a supported region (e.g., `us-central1`). Multi-region locations (e.g., `us`) are not allowed.  \n",
        "- The input table must include a `request` column of type `JSON` or `STRING` containing valid JSON, structured as a [`GenerateContentRequest`](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference).  \n",
        "- Additional columns can use any BigQuery data types except `array`, `struct`, `range`, `datetime`, and `geography`. These are ignored for generation but appear in the output table. The system reserves `response` and `status` for output.  \n",
        "- Only public YouTube or Cloud Storage URIs are supported in the `fileData` or `file_data` field.  \n",
        "- Requests can include parameters to customize the model's output. Learn more in the [Gemini parameters guide](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "835bfd485d49"
      },
      "source": [
        "This is an example BigQuery table with sample requests:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b932f02d1f9c"
      },
      "outputs": [],
      "source": [
        "INPUT_DATA = \"bq://storage-samples.generative_ai.batch_requests_for_multimodal_input_2\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d62eb771ad6"
      },
      "source": [
        "You can query the BigQuery table to review the input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbfcefb7d295"
      },
      "outputs": [],
      "source": [
        "bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "bq_table_id = INPUT_DATA.replace(\"bq://\", \"\")\n",
        "sql = f\"\"\"\n",
        "        SELECT *\n",
        "        FROM {bq_table_id}\n",
        "        \"\"\"\n",
        "\n",
        "query_result = bq_client.query(sql)\n",
        "\n",
        "df = query_result.result().to_dataframe()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "529dae543bfc"
      },
      "source": [
        "### Prepare batch output location\n",
        "\n",
        "When a batch prediction task completes, the output is stored in the location that you specified in your request.\n",
        "\n",
        "- The location is in the form of a BigQuery URI prefix, for example: `bq://projectId.bqDatasetId`.\n",
        "- If not specified, `bq://PROJECT_ID.gen_ai_batch_prediction.predictions_TIMESTAMP` will be used.\n",
        "\n",
        "This tutorial uses a **BigQuery** table as an example.\n",
        "\n",
        "- You can specify the URI of your BigQuery table in `BQ_OUTPUT_URI`, or\n",
        "- If it is not specified, this notebook will create a new dataset `bq://PROJECT_ID.gen_ai_batch_prediction` for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75914840e555"
      },
      "outputs": [],
      "source": [
        "BQ_OUTPUT_URI = \"[your-bigquery-table]\"  # @param {type:\"string\"}\n",
        "\n",
        "if BQ_OUTPUT_URI == \"[your-bigquery-table]\":\n",
        "    bq_dataset_id = \"gen_ai_batch_prediction\"\n",
        "\n",
        "    # The output table will be created automatically if it doesn't exist\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "    bq_table_id = f\"prediction_result_{timestamp}\"\n",
        "    BQ_OUTPUT_URI = f\"bq://{PROJECT_ID}.{bq_dataset_id}.{bq_table_id}\"\n",
        "\n",
        "    bq_dataset = bigquery.Dataset(f\"{PROJECT_ID}.{bq_dataset_id}\")\n",
        "    bq_dataset.location = \"us-central1\"\n",
        "\n",
        "    bq_dataset = bq_client.create_dataset(bq_dataset, exists_ok=True, timeout=30)\n",
        "    print(\n",
        "        f\"Created BigQuery dataset {bq_client.project}.{bq_dataset.dataset_id} for batch prediction output.\"\n",
        "    )\n",
        "\n",
        "print(f\"BigQuery output URI: {BQ_OUTPUT_URI}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14f84475dc26"
      },
      "source": [
        "### Send a batch prediction request\n",
        "\n",
        "To make a batch prediction request, you specify a source model ID, an input source and an output location where Vertex AI stores the batch prediction results.\n",
        "\n",
        "To learn more, see the [Batch prediction API](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/batch-prediction-api) page.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e809955e753b"
      },
      "outputs": [],
      "source": [
        "bq_batch_job = client.batches.create(\n",
        "    model=MODEL_ID,\n",
        "    src=INPUT_DATA,\n",
        "    config=CreateBatchJobConfig(dest=BQ_OUTPUT_URI),\n",
        ")\n",
        "bq_batch_job.name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fcb3dc2a5fc"
      },
      "source": [
        "Print out the job status and other properties. You can also check the status in the Cloud Console at https://console.cloud.google.com/vertex-ai/batch-predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b19319d92bf0"
      },
      "outputs": [],
      "source": [
        "bq_batch_job = client.batches.get(name=bq_batch_job.name)\n",
        "bq_batch_job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e72800144910"
      },
      "source": [
        "Optionally, you can list all the batch prediction jobs in the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a9fb087f9ba"
      },
      "outputs": [],
      "source": [
        "for job in client.batches.list():\n",
        "    print(job.name, job.create_time, job.state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebcb00b3add9"
      },
      "source": [
        "### Wait for the batch prediction job to complete\n",
        "\n",
        "Depending on the number of input items that you submitted, a batch generation task can take some time to complete. You can use the following code to check the job status and wait for the job to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "189945468c6b"
      },
      "outputs": [],
      "source": [
        "# Refresh the job until complete\n",
        "while bq_batch_job.state == \"JOB_STATE_RUNNING\":\n",
        "    time.sleep(5)\n",
        "    bq_batch_job = client.batches.get(name=bq_batch_job.name)\n",
        "\n",
        "# Check if the job succeeds\n",
        "if bq_batch_job.state == \"JOB_STATE_SUCCEEDED\":\n",
        "    print(\"Job succeeded!\")\n",
        "else:\n",
        "    print(f\"Job failed: {bq_batch_job.error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec25f40f0dd9"
      },
      "source": [
        "### Retrieve batch prediction results\n",
        "\n",
        "When a batch prediction task is complete, the output of the prediction is stored in the location that you specified in your request. It is also available in `batch_job.dest.bigquery_uri` or `batch_job.dest.gcs_uri`.\n",
        "\n",
        "- When you are using BigQuery, the output of batch prediction is stored in an output dataset. If you had provided a dataset, the name of the dataset (`BQ_OUTPUT_URI`) is the name you had provided earlier. \n",
        "- If you did not provide an output dataset, a default dataset `bq://PROJECT_ID.gen_ai_batch_prediction` will be created for you.\n",
        "- The name of the table is formed by appending `predictions_` with the timestamp of when the batch prediction job started."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c459121f0169"
      },
      "source": [
        "You can use the example code below to retrieve predictions and store them into a Pandas DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca8b73b0ad1b"
      },
      "outputs": [],
      "source": [
        "bq_table_id = bq_batch_job.dest.bigquery_uri.replace(\"bq://\", \"\")\n",
        "\n",
        "sql = f\"\"\"\n",
        "        SELECT *\n",
        "        FROM {bq_table_id}\n",
        "        \"\"\"\n",
        "\n",
        "query_result = bq_client.query(sql)\n",
        "\n",
        "df = query_result.result().to_dataframe()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a4e033321ad"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "Clean up resources created in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNCyIKIrdPJY"
      },
      "outputs": [],
      "source": [
        "# Delete the batch prediction jobs\n",
        "if gcs_batch_job:\n",
        "    client.batches.delete(name=gcs_batch_job.name)\n",
        "if bq_batch_job:\n",
        "    client.batches.delete(name=bq_batch_job.name)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_batch_prediction.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
